{"dependencies":{"<BlockHashes as std::cmp::PartialEq>::eq":["BlockHashes","std::collections::HashMap","std::marker::Sized"],"<BlockHashes as std::fmt::Debug>::fmt":["BlockHashes","std::collections::HashMap","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<Delete as std::cmp::PartialEq>::eq":["Delete"],"<Delete as std::fmt::Debug>::fmt":["Delete","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<Diff as std::cmp::PartialEq>::eq":["Diff","std::alloc::Allocator","std::marker::Sized","std::vec::Vec"],"<Diff as std::fmt::Debug>::fmt":["Diff","std::alloc::Allocator","std::fmt::Formatter","std::marker::Sized","std::result::Result","std::vec::Vec"],"<Insert as std::cmp::PartialEq>::eq":["Insert","std::alloc::Allocator","std::marker::Sized","std::vec::Vec"],"<Insert as std::fmt::Debug>::fmt":["Insert","std::alloc::Allocator","std::fmt::Formatter","std::marker::Sized","std::result::Result","std::vec::Vec"],"<string_diff::EditDistance as string_diff::OperationScore>::delete_score":["string_diff::EditDistance"],"<string_diff::EditDistance as string_diff::OperationScore>::insert_score":["string_diff::EditDistance"],"<string_diff::EditDistance as string_diff::OperationScore>::match_score":["string_diff::EditDistance"],"<string_diff::EditDistance as string_diff::OperationScore>::substitution_score":["string_diff::EditDistance"],"BlockHashes":["BlockHashes","std::collections::HashMap","std::marker::Sized"],"Delete":["Delete"],"Delete::compress_to":["Delete","std::io::Write","std::marker::Sized","std::result::Result"],"Delete::expand_from":["std::io::Read","std::marker::Sized","std::result::Result"],"Delete::get_length":["Delete"],"Delete::get_position":["Delete"],"Diff":["Diff","std::alloc::Allocator","std::marker::Sized","std::vec::Vec"],"Diff::add_delete":["Diff","std::alloc::Allocator","std::marker::Sized","std::vec::Vec"],"Diff::add_insert":["Diff","std::alloc::Allocator","std::marker::Sized","std::vec::Vec"],"Diff::apply":["Diff","std::alloc::Allocator","std::fs::File","std::marker::Sized","std::result::Result","std::vec::Vec"],"Diff::apply_to_string":["Diff","std::alloc::Allocator","std::marker::Sized","std::result::Result","std::vec::Vec"],"Diff::compress_to":["Diff","std::alloc::Allocator","std::io::Write","std::marker::Sized","std::result::Result","std::vec::Vec"],"Diff::deletes":["Diff","std::alloc::Allocator","std::marker::Sized","std::slice::Iter","std::vec::Vec"],"Diff::expand_from":["std::io::Read","std::marker::Sized","std::result::Result"],"Diff::inserts":["Diff","std::alloc::Allocator","std::marker::Sized","std::slice::Iter","std::vec::Vec"],"Diff::is_empty":["Diff","std::alloc::Allocator","std::marker::Sized","std::vec::Vec"],"Diff::new":["Diff","std::alloc::Allocator","std::marker::Sized","std::vec::Vec"],"Insert":["Insert","std::alloc::Allocator","std::marker::Sized","std::vec::Vec"],"Insert::compress_to":["Insert","std::alloc::Allocator","std::io::Write","std::marker::Sized","std::result::Result","std::vec::Vec"],"Insert::expand_from":["std::io::Read","std::marker::Sized","std::result::Result"],"Insert::get_data":["Insert","std::alloc::Allocator","std::marker::Sized","std::vec::Vec"],"Insert::get_position":["Insert","std::alloc::Allocator","std::marker::Sized","std::vec::Vec"],"Window":["Window","std::alloc::Allocator","std::io::Read","std::marker::Sized","std::vec::Vec"],"hashing::<impl BlockHashes>::check_match":["BlockHashes","Window","crypto::md5::Md5","hashing::RollingHash","std::alloc::Allocator","std::collections::HashMap","std::io::Read","std::marker::Sized","std::option::Option","std::vec::Vec"],"hashing::<impl BlockHashes>::compress_to":["BlockHashes","std::collections::HashMap","std::io::Write","std::marker::Sized","std::result::Result"],"hashing::<impl BlockHashes>::diff_and_update":["BlockHashes","std::collections::HashMap","std::io::Read","std::marker::Sized","std::result::Result"],"hashing::<impl BlockHashes>::empty":["BlockHashes","std::collections::HashMap","std::marker::Sized"],"hashing::<impl BlockHashes>::expand_from":["std::io::Read","std::marker::Sized","std::result::Result"],"hashing::<impl BlockHashes>::hash_match":["BlockHashes","Window","crypto::md5::Md5","hashing::RollingHash","std::alloc::Allocator","std::collections::HashMap","std::io::Read","std::marker::Sized","std::option::Option","std::vec::Vec"],"hashing::<impl BlockHashes>::new":["std::io::Read","std::marker::Sized","std::result::Result"],"hashing::<impl BlockHashes>::verify_unchanged":["BlockHashes","std::collections::HashMap","std::io::Read","std::marker::Sized","std::result::Result"],"hashing::RollingHash":["hashing::RollingHash"],"hashing::RollingHash::get_hash":["hashing::RollingHash"],"hashing::RollingHash::hash_buffer":[],"hashing::RollingHash::new":["hashing::RollingHash","std::iter::Iterator","std::marker::Sized"],"hashing::RollingHash::roll_hash":["hashing::RollingHash","std::marker::Sized","std::option::Option"],"string_diff::EditDistance":["string_diff::EditDistance"],"string_diff::OperationScore::delete_score":[],"string_diff::OperationScore::insert_score":[],"string_diff::OperationScore::match_score":[],"string_diff::OperationScore::substitution_score":[],"string_diff::find_diff":["Diff","std::alloc::Allocator","std::marker::Sized","std::vec::Vec","string_diff::EditDistance","string_diff::OperationScore"],"string_diff::hirschberg":["Diff","std::alloc::Allocator","std::marker::Sized","std::vec::Vec","string_diff::EditDistance","string_diff::OperationScore"],"string_diff::nw_score":["std::alloc::Allocator","std::marker::Sized","std::vec::Vec","string_diff::EditDistance","string_diff::OperationScore"],"window::<impl Window<R>>::advance":["Window","std::alloc::Allocator","std::io::Read","std::marker::Sized","std::result::Result","std::vec::Vec"],"window::<impl Window<R>>::frame":["Window","std::alloc::Allocator","std::io::Read","std::marker::Sized","std::vec::Vec"],"window::<impl Window<R>>::frame_size":["Window","std::alloc::Allocator","std::io::Read","std::marker::Sized","std::vec::Vec"],"window::<impl Window<R>>::get_bytes_read":["Window","std::alloc::Allocator","std::io::Read","std::marker::Sized","std::vec::Vec"],"window::<impl Window<R>>::get_head":["Window","std::alloc::Allocator","std::io::Read","std::marker::Sized","std::option::Option","std::vec::Vec"],"window::<impl Window<R>>::load_next_block":["Window","std::alloc::Allocator","std::io::Read","std::marker::Sized","std::result::Result","std::vec::Vec"],"window::<impl Window<R>>::new":["std::marker::Sized","std::result::Result"],"window::<impl Window<R>>::on_boundry":["Window","std::alloc::Allocator","std::io::Read","std::marker::Sized","std::vec::Vec"]},"glob_path_import":{},"self_to_fn":{"BlockHashes":["Debug","PartialEq","impl BlockHashes {\n\n    /// Create a new BlockHash based on the data in data_source.  This method\n    /// will create a hash for every `block_size` set of bytes in `data_source`.\n    ///\n    /// To see the difference after `data_source` has been updated, use `diff_and_update()`\n    ///\n    /// This method returns an error when there is a problem reading from `data_source`.\n    pub fn new<R: Read>(mut data_source: R, block_size: usize) -> Result<BlockHashes> {\n        let mut block = vec![0;block_size];\n        let mut hashes = HashMap::new();\n        let mut block_index = 0;\n        let mut strong_hasher = Md5::new();\n        let mut total_size = 0;\n\n        let mut read_size = try!(data_source.read(&mut block));\n        while read_size > 0 {\n            let weak_hash = RollingHash::hash_buffer(&block[..read_size]);\n\n            let mut strong_hash:[u8;16] = [0;16];\n            strong_hasher.reset();\n            strong_hasher.input(&block[..read_size]);\n            strong_hasher.result(&mut strong_hash);\n\n            hashes.entry(weak_hash).or_insert(Vec::new()).push((block_index, strong_hash));\n\n            block_index += 1;\n            total_size += read_size;\n            read_size = try!(data_source.read(&mut block));\n        }\n        Ok(BlockHashes {\n            hashes: hashes,\n            block_size: block_size,\n            file_size: total_size\n        })\n    }\n\n    /// Construct a new block hash for a file that was just created\n    pub fn empty(block_size: usize) -> BlockHashes {\n        BlockHashes {\n            hashes: HashMap::new(),\n            block_size: block_size,\n            file_size: 0\n        }\n    }\n\n    /// Compare the data in `new_data` with the hashes computed from either\n    /// the most recent call to `diff_and_update()` or when this `BlockHashes` was updated\n    ///\n    /// # Example\n    ///\n    /// ```\n    /// use rdiff::BlockHashes;\n    /// use std::io::Cursor;\n    /// let mut hashes = BlockHashes::new(Cursor::new(\"It was the best of times\"), 6).unwrap();\n    /// let diff = hashes.diff_and_update(Cursor::new(\"It was not the best of things\")).unwrap();\n    /// // prints (6, ' not') and (22, ' things'))\n    /// for insert in diff.inserts() {\n    ///     println!(\"{:?}\", insert);\n    /// }\n    /// // prints (29, 6)\n    /// for delete in diff.deletes() {\n    ///     println!(\"{:?}\", delete);\n    /// }\n    /// assert_eq!(\"It was not the best of things\",\n    ///             diff.apply_to_string(\"It was the best of times\").unwrap());\n    /// ```\n    pub fn diff_and_update<R: Read>(&mut self, new_data: R) -> Result<Diff> {\n        use std::mem;\n        let mut diffs = Diff::new();\n        let mut window = try!(Window::new(new_data, self.block_size));\n        let mut weak_hasher = RollingHash::new(window.frame().0.iter());\n        let mut strong_hasher = Md5::new();\n        let mut last_matching_block_index = -1;\n        let mut insert_buffer = Vec::new();\n        let mut new_hashes = HashMap::new();\n        let mut current_block_index = 0;\n        while window.frame_size() > 0 {\n\n            if let Some(other_block_index) = self.check_match(&weak_hasher, &mut strong_hasher, &mut window, &mut last_matching_block_index) {\n                //create an insert if the insert buffer has anything in it\n                if insert_buffer.len() > 0 {\n                    // XXX with some work here, we could probably track the insert buffer as a piece of the window, which is then\n                    // moved into the diff list.\n                    diffs.add_insert(window.get_bytes_read() - insert_buffer.len(), mem::replace(&mut insert_buffer, Vec::new()));\n                }\n                //create a delete if the index is more than it should be\n                if other_block_index as i32 > last_matching_block_index + 1 {\n                    diffs.add_delete(window.get_bytes_read(), self.block_size * (other_block_index as i32 - last_matching_block_index - 1) as usize)\n                }\n                last_matching_block_index = other_block_index as i32;\n                //advance forward an entire block's worth\n                for i in 0..self.block_size {\n                    if window.on_boundry() {\n                        // This might iterate past the end of the data.  If so, bail out\n                        if window.frame_size() == 0 {\n                            break;\n                        }\n                        let mut strong_hash:[u8;16] = [0;16];\n                        // If the boundry happened where we saw a match, we can skip the\n                        // strong hashing, because it was already done during the\n                        // match checking\n                        if i != 0 {\n                            let (front, back) = window.frame();\n                            strong_hasher.reset();\n                            strong_hasher.input(front);\n                            strong_hasher.input(back);\n                        }\n                        strong_hasher.result(&mut strong_hash);\n\n                        new_hashes.entry(weak_hasher.get_hash()).or_insert(Vec::new()).push((current_block_index, strong_hash));\n                        current_block_index += 1;\n                    }\n                    let (tail, head) = try!(window.advance());\n                    if let Some(tail) = tail {\n                        weak_hasher.roll_hash(head, tail);\n                    } else {\n                        break;\n                    }\n                }\n            } else {\n                //advance forward one byte\n                if window.on_boundry() {\n                    // XXX There is a slight optimization possible here, where\n                    // when the weak checksum matches, but the strong one doesn't\n                    // we are re-computing the strong checksum here.\n                    let mut strong_hash:[u8;16] = [0;16];\n                    let (front, back) = window.frame();\n                    strong_hasher.reset();\n                    strong_hasher.input(front);\n                    strong_hasher.input(back);\n                    strong_hasher.result(&mut strong_hash);\n\n                    new_hashes.entry(weak_hasher.get_hash()).or_insert(Vec::new()).push((current_block_index, strong_hash));\n                    current_block_index += 1;\n                }\n                let (tail, head) = try!(window.advance());\n                weak_hasher.roll_hash(head, tail.unwrap());\n                insert_buffer.push(tail.unwrap());\n            }\n        }\n        if insert_buffer.len() > 0 {\n            diffs.add_insert(window.get_bytes_read() - insert_buffer.len(), insert_buffer);\n        }\n        let old_block_count = (self.file_size + self.block_size - 1) as i32 / self.block_size as i32;\n        if last_matching_block_index + 1 < old_block_count {\n            diffs.add_delete(window.get_bytes_read(), (self.file_size as i32 - (last_matching_block_index + 1) * self.block_size as i32) as usize);\n        }\n        self.hashes = new_hashes;\n        self.file_size = window.get_bytes_read();\n        Ok(diffs)\n    }\n\n    /// Checks if `data_source` has changed since the last time the hashes were updated.\n    ///\n    /// Returns true if `data_source` is identical to what it was when the hashes were generated, false otherwise\n    pub fn verify_unchanged<R: Read>(&self, data_source: &mut R) -> Result<bool> {\n        let mut block = vec![0;self.block_size];\n        let mut block_index = 0;\n        let mut strong_hasher = Md5::new();\n        let mut total_size = 0;\n\n        let mut read_size = try!(data_source.read(&mut block));\n        while read_size > 0 {\n            let weak_hash = RollingHash::hash_buffer(&block[..read_size]);\n            if let Some(entry) = self.hashes.get(&weak_hash) {\n                let mut strong_hash:[u8;16] = [0;16];\n                strong_hasher.reset();\n                strong_hasher.input(&block[..read_size]);\n                strong_hasher.result(&mut strong_hash);\n                if !entry.contains(&(block_index, strong_hash)) {\n                    return Ok(false);\n                }\n            }\n\n\n            block_index += 1;\n            total_size += read_size;\n            read_size = try!(data_source.read(&mut block));\n        }\n        Ok(total_size == self.file_size)\n    }\n\n    /// Compress these Hashes and write to `writer`.  The output can then be expanded\n    /// back into an equivilent Hash collection using `expand_from()`\n    pub fn compress_to<W: Write>(&self, writer: &mut W) -> Result<()> {\n\n        let mut int_buf = [0;4];\n        NetworkEndian::write_u32(&mut int_buf, self.file_size as u32);\n        try!(writer.write(&int_buf));\n        NetworkEndian::write_u32(&mut int_buf, self.block_size as u32);\n        try!(writer.write(&int_buf));\n        let block_count = (self.file_size + self.block_size - 1) / self.block_size;\n        let dummy_hash = [0u8;16];\n        let mut sequential_hashes = Vec::with_capacity(block_count);\n        sequential_hashes.resize(block_count, (0, &dummy_hash));\n        for (weak_hash, entry) in self.hashes.iter() {\n            for &(index, ref strong_hash) in entry.iter() {\n                sequential_hashes[index] = (*weak_hash, strong_hash);\n            }\n        }\n        for (weak, strong) in sequential_hashes {\n            NetworkEndian::write_u32(&mut int_buf, weak);\n            try!(writer.write(&int_buf));\n            try!(writer.write(strong));\n        }\n        Ok(())\n    }\n\n    /// Expand these hashes from previously compressed data in `reader`.  The data in reader\n    /// should have been written using `compress_to()`\n    pub fn expand_from<R: Read>(reader: &mut R) -> Result<BlockHashes> {\n        let mut int_buf = [0;4];\n        let mut strong_hash = [0u8;16];\n        try!(reader.read(&mut int_buf));\n        let file_size = NetworkEndian::read_u32(&mut int_buf) as usize;\n        try!(reader.read(&mut int_buf));\n        let block_size = NetworkEndian::read_u32(&mut int_buf) as usize;\n        let block_count = (file_size + block_size - 1) / block_size;\n        // Might be an overestimate, but not by more than a few\n        let mut hashes = HashMap::with_capacity(block_count);\n\n        for block_index in 0..block_count {\n            try!(reader.read(&mut int_buf));\n            let weak_hash = NetworkEndian::read_u32(&mut int_buf);\n            try!(reader.read(&mut strong_hash));\n            hashes.entry(weak_hash).or_insert(Vec::new()).push((block_index, strong_hash));\n        }\n        Ok(BlockHashes {\n            file_size: file_size,\n            block_size: block_size,\n            hashes: hashes\n        })\n    }\n\n    /// Checks if the current window frame matches any existing block with an index greater than the previously matched block.\n    ///\n    /// Returns the index of the matching block if it does\n    fn check_match<R: Read>(&self, weak_hasher: &RollingHash, mut strong_hasher: &mut Md5, mut window: &Window<R>, last_matching_block_index: &mut i32) -> Option<usize> {\n        if let Some(other_block_index) = self.hash_match(&weak_hasher, &mut strong_hasher, &mut window) {\n            if other_block_index as i32 > *last_matching_block_index {\n                return Some(other_block_index);\n            }\n        }\n        None\n    }\n\n    /// Checks to see if the hash of the current window frame matches an existing hash.\n    ///\n    /// If so, returns the index of the matching block\n    fn hash_match<R: Read>(&self, weak_hasher: &RollingHash,  strong_hasher: &mut Md5, window: &Window<R>) -> Option<usize> {\n        let mut new_result = [0;16];\n        if let Some(matches) = self.hashes.get(&weak_hasher.get_hash()) {\n            for &(index, strong_hash) in matches.iter() {\n                strong_hasher.reset();\n                let (front, back) = window.frame();\n                strong_hasher.input(front);\n                strong_hasher.input(back);\n                strong_hasher.result(&mut new_result);\n                if new_result == strong_hash {\n                    return Some(index)\n                }\n            }\n        }\n        return None\n    }\n}"],"Delete":["PartialEq","impl Delete {\n    /// Gets the byte position of this delete operation in its file\n    #[inline]\n    pub fn get_position(&self) -> usize {\n        self.position\n    }\n\n    /// Gets the length in bytes of this delete operation\n    #[inline]\n    pub fn get_length(&self) -> usize {\n        self.len\n    }\n\n    /// Compress this operation and write to `writer`.  The output can then be expanded\n    /// back into an equivilent operation using `expand_from()`\n    pub fn compress_to<W: Write>(&self, writer: &mut W) -> io::Result<()> {\n\n        let mut int_buf = [0;4];\n        NetworkEndian::write_u32(&mut int_buf, self.position as u32);\n        try!(writer.write(&int_buf));\n        NetworkEndian::write_u32(&mut int_buf, self.len as u32);\n        try!(writer.write(&int_buf));\n        Ok(())\n    }\n\n    /// Expand this operation from previously compressed data in `reader`.  The data in reader\n    /// should have been written using `compress_to()`\n    pub fn expand_from<R: Read>(reader: &mut R) -> io::Result<Delete> {\n        let mut int_buf = [0;4];\n        try!(reader.read_exact(&mut int_buf));\n        let position = NetworkEndian::read_u32(&int_buf);\n        try!(reader.read_exact(&mut int_buf));\n        let len = NetworkEndian::read_u32(&int_buf);\n        Ok(Delete{\n            position: position as usize,\n            len: len as usize,\n        })\n    }\n\n}","impl fmt::Debug for Delete {\n    fn fmt(&self, fmt: &mut fmt::Formatter) -> fmt::Result {\n        write!(fmt, \"Delete({}, {})\", self.position, self.len)\n    }\n}"],"Diff":["Debug","PartialEq","impl Diff {\n    /// Creates a new `Diff`\n    #[inline]\n    pub fn new() -> Diff {\n        Diff {\n            inserts: Vec::new(),\n            deletes: Vec::new()\n        }\n    }\n\n    /// Adds an insert operation into this diff.  The operation must occur after\n    /// all previously added insert operations in file order.  If the operation\n    /// can be merged with the previous operation, then it is.\n    ///\n    /// Consumes the data that is passed in\n    fn add_insert(&mut self, position: usize, mut data: Vec<u8>) {\n        if let Some(tail) = self.inserts.last_mut() {\n            if tail.position + tail.data.len() == position {\n                tail.data.append(&mut data);\n                return;\n            }\n        }\n        self.inserts.push(Insert {\n            position: position,\n            data: data\n        });\n    }\n\n    // Adds an delete operation into this diff.  The operation must occur after\n    /// all previously added insert and delete operations in file order.  If the operation\n    /// can be merged with the previous operation, then it is.\n    fn add_delete(&mut self, position: usize, len: usize) {\n        if let Some(tail) = self.deletes.last_mut() {\n            if tail.position  == position {\n                tail.len += len;\n                return;\n            }\n        }\n        self.deletes.push(Delete {\n            position: position,\n            len: len\n        });\n    }\n\n    /// Gets an iterator over all insert operations\n    pub fn inserts(&self) -> Iter<Insert> {\n        self.inserts.iter()\n    }\n\n    /// Gets an iterator over all delete operations\n    pub fn deletes(&self) -> Iter<Delete> {\n        self.deletes.iter()\n    }\n\n    /// Checks if this set of diffs has any actual content\n    pub fn is_empty(&self) -> bool {\n        self.deletes.is_empty() && self.inserts.is_empty()\n    }\n\n    /// Applies all of the operations in the diff to the given string.\n    /// Gives an error if the resulting string can't be represented by utf8.\n    ///\n    /// # Panics\n    /// When the operations refer to positions that are not represented by the string.\n    pub fn apply_to_string(&self, string: &str) -> Result<String, FromUtf8Error> {\n        let mut old_bytes = string.bytes();\n        let mut new_bytes = Vec::new();\n        let mut index = 0;\n        for insert in self.inserts() {\n            while index < insert.position {\n                new_bytes.push(old_bytes.next().unwrap().clone());\n                index += 1;\n            }\n            new_bytes.append(&mut insert.data.clone());\n            index += insert.data.len();\n        }\n        while let Some(byte) = old_bytes.next() {\n            new_bytes.push(byte);\n        }\n        let old_bytes = mem::replace(&mut new_bytes, Vec::new());\n        let mut  old_bytes = old_bytes.into_iter();\n        index = 0;\n        for delete in self.deletes() {\n            while index < delete.position {\n                new_bytes.push(old_bytes.next().unwrap());\n                index += 1;\n            }\n            for _ in 0..delete.len {\n                old_bytes.next();\n            }\n        }\n        while let Some(byte) = old_bytes.next() {\n            new_bytes.push(byte);\n        }\n        String::from_utf8(new_bytes)\n    }\n\n    /// Apply the operations in this sequence to a file.  This should not be called until after\n    /// the sequence has been integrated via [`Engine::integrate_remote`](struct.Engine.html#method.integrate_remote)\n    /// The file must have been opened on both read and write mode (see [OpenOptions](https://doc.rust-lang.org/nightly/std/fs/struct.OpenOptions.html)).\n    pub fn apply(&self, file: &mut File) -> io::Result<()> {\n        let mut new_bytes = Vec::new();\n        try!(file.seek(SeekFrom::Start(0)));\n        let mut old_bytes = file.try_clone().unwrap().bytes();\n        let mut index = 0;\n        for insert in self.inserts.iter() {\n            while index < insert.position {\n                new_bytes.push(try!(old_bytes.next().unwrap()).clone());\n                index += 1;\n            }\n            new_bytes.extend_from_slice(&insert.data[..]);\n            index += insert.data.len();\n        }\n        while let Some(byte) = old_bytes.next() {\n            new_bytes.push(try!(byte));\n        }\n        let old_bytes = mem::replace(&mut new_bytes, Vec::new());\n        let mut old_bytes = old_bytes.into_iter();\n        index = 0;\n        for delete in self.deletes.iter() {\n            while index < delete.position {\n                new_bytes.push(old_bytes.next().unwrap());\n                index += 1;\n            }\n            for _ in 0..delete.len {\n                old_bytes.next();\n            }\n        }\n        while let Some(byte) = old_bytes.next() {\n            new_bytes.push(byte);\n        }\n\n        try!(file.seek(SeekFrom::Start(0)));\n        try!(file.set_len(new_bytes.len() as u64));\n        file.write_all(new_bytes.as_slice())\n    }\n\n    /// Compress this diff and write to `writer`.  The output can then be expanded\n    /// back into an equivilent Diff using `expand_from()`\n    pub fn compress_to<W: Write>(&self, writer: &mut W) -> io::Result<()> {\n\n        let mut int_buf = [0;4];\n        NetworkEndian::write_u32(&mut int_buf, self.inserts.len() as u32);\n        try!(writer.write(&mut int_buf));\n        for insert in self.inserts.iter() {\n            try!(insert.compress_to(writer));\n        }\n        NetworkEndian::write_u32(&mut int_buf, self.deletes.len() as u32);\n        try!(writer.write(&mut int_buf));\n        for delete in self.deletes.iter() {\n            try!(delete.compress_to(writer));\n        }\n        Ok(())\n    }\n\n    /// Expand this diff from previously compressed data in `reader`.  The data in reader\n    /// should have been written using `compress_to()`\n    pub fn expand_from<R: Read>(reader: &mut R) -> io::Result<Diff> {\n        let mut int_buf = [0;4];\n\n        trace!(\"Reading insert length\");\n        try!(reader.read_exact(&mut int_buf));\n        let insert_len = NetworkEndian::read_u32(&int_buf);\n        trace!(\"Insert length was: {}\", insert_len);\n        let inserts = (0..insert_len).map(|_|Insert::expand_from(reader).unwrap()).collect();\n        trace!(\"Read inserts\");\n        trace!(\"Reading delete length\");\n        try!(reader.read_exact(&mut int_buf));\n        let delete_len = NetworkEndian::read_u32(&int_buf);\n        trace!(\"Delete length was: {}\", delete_len);\n        let deletes = (0..delete_len).map(|_|Delete::expand_from(reader).unwrap()).collect();\n        trace!(\"Read deletes\");\n        Ok(Diff {\n            inserts: inserts,\n            deletes: deletes\n        })\n    }\n}"],"Insert":["PartialEq","impl Insert {\n    /// Gets the byte position of this insert operation in its file\n    #[inline]\n    pub fn get_position(&self) -> usize {\n        self.position\n    }\n\n    /// Gets the data this insert operation will insert\n    #[inline]\n    pub fn get_data(&self) -> &Vec<u8> {\n        &self.data\n    }\n\n    /// Compress this operation and write to `writer`.  The output can then be expanded\n    /// back into an equivilent operation using `expand_from()`\n    pub fn compress_to<W: Write>(&self, writer: &mut W) -> io::Result<()> {\n\n        let mut int_buf = [0;4];\n        NetworkEndian::write_u32(&mut int_buf, self.position as u32);\n        try!(writer.write(&int_buf));\n        NetworkEndian::write_u32(&mut int_buf, self.data.len() as u32);\n        try!(writer.write(&int_buf));\n        try!(writer.write(&self.data));\n        Ok(())\n    }\n\n    /// Expand this operation from previously compressed data in `reader`.  The data in reader\n    /// should have been written using `compress_to()`\n    pub fn expand_from<R: Read>(reader: &mut R) -> io::Result<Insert> {\n        let mut int_buf = [0;4];\n        try!(reader.read_exact(&mut int_buf));\n        let position = NetworkEndian::read_u32(&int_buf);\n        try!(reader.read_exact(&mut int_buf));\n        let data_len = NetworkEndian::read_u32(&int_buf) as usize;\n        let mut data = Vec::with_capacity(data_len);\n        data.resize(data_len, 0);\n        try!(reader.read_exact(&mut data));\n        Ok(Insert{\n            position: position as usize,\n            data: data\n        })\n    }\n\n}","impl fmt::Debug for Insert {\n    fn fmt(&self, fmt: &mut fmt::Formatter) -> fmt::Result {\n        write!(fmt, \"Insert({}, '{}')\", self.position, String::from_utf8_lossy(&self.data).replace('\\r', \"\").replace('\\n', \"\\\\n\"))\n    }\n}"],"Window":["impl<R:Read> Window<R> {\n    pub fn new(mut reader:R, block_size: usize) -> Result<Window<R>> {\n        let mut front = vec!(0;block_size);\n        let mut back = vec!(0;block_size);\n        let size = try!(reader.read(front.as_mut_slice()));\n        unsafe {\n            front.set_len(size);\n        }\n        let size = try!(reader.read(back.as_mut_slice()));\n        unsafe {\n            back.set_len(size);\n        }\n        Ok(Window {\n            front: front,\n            back: back,\n            block_size: block_size,\n            offset: 0,\n            reader: reader,\n            bytes_read: 0\n        })\n    }\n\n    pub fn advance(&mut self) -> Result<(Option<u8>, Option<u8>)> {\n        if self.front.len() == 0 {\n            return Ok((None, None));\n        }\n\n        if self.offset >= self.front.len() {\n            if self.back.len() == 0 {\n                return Ok((None, None));\n            }\n            try!(self.load_next_block());\n        }\n        let tail = self.front[self.offset];\n        let head = self.get_head();\n        self.offset += 1;\n        self.bytes_read += 1;\n        Ok((Some(tail), head))\n    }\n\n    fn get_head(&self) -> Option<u8> {\n        let head_index = self.offset + self.block_size - self.front.len();\n        if head_index >= self.back.len() {\n            return None;\n        }\n        return Some(self.back[head_index]);\n    }\n\n    fn load_next_block(&mut self) -> Result<()> {\n        // We've gone past the end of the front half\n        self.front = mem::replace(&mut self.back, vec!(0;self.block_size));\n        let size = try!(self.reader.read(self.back.as_mut_slice()));\n        unsafe{\n            self.back.set_len(size);\n        }\n        self.offset = 0;\n        Ok(())\n    }\n\n    pub fn frame<'a>(&'a self) -> (&'a [u8], &'a [u8]) {\n        let front_offset = min(self.offset, self.front.len());\n        let back_offset = min(self.offset, self.back.len());\n        (&self.front[front_offset..], &self.back[..back_offset])\n    }\n\n    pub fn frame_size(&self) -> usize {\n        self.front.len() + self.back.len() - self.offset\n    }\n\n    pub fn on_boundry(&self) -> bool {\n        self.offset == 0 || self.offset == self.front.len()\n    }\n\n    pub fn get_bytes_read(&self) -> usize {\n        self.bytes_read\n    }\n}"],"hashing::RollingHash":["impl RollingHash {\n\n    /// Creates a new rolling hash over the bytes in `initial_data`.\n    /// It will be assumed that the size of blocks will be the size of the initial data.\n    pub fn new<'a, I: Iterator<Item=&'a u8>>(initial_data: I) -> RollingHash {\n\n        let mut a:u16 = 0;\n        let mut b:u16 = 0;\n        let mut block_size: u16 = 0;\n        for byte in initial_data {\n            a = a.wrapping_add(*byte as u16);\n            b = b.wrapping_add(a);\n            block_size += 1;\n        }\n        RollingHash {\n            a: a,\n            b: b,\n            block_size: block_size\n        }\n    }\n\n    /// Gets the hash as it currently stands\n    pub fn get_hash(&self) -> u32 {\n        return (self.b as u32) << 16 | self.a as u32;\n    }\n\n    /// Roll the has forward one byte.  This function will remove `old_byte` from its calculation\n    /// and add `new_byte` if it exists.\n    /// To get the hash afterwards, use `get_hash()`.\n    pub fn roll_hash(&mut self, new_byte: Option<u8>, old_byte: u8) {\n        self.a = self.a.wrapping_sub(old_byte as u16);\n        self.b = self.b.wrapping_sub(((old_byte as u16).wrapping_mul(self.block_size as u16)) as u16);\n        if let Some(new_byte) = new_byte {\n            self.a = self.a.wrapping_add(new_byte as u16);\n            self.b = self.b.wrapping_add(self.a);\n        } else {\n            self.block_size -= 1\n        }\n    }\n\n    /// Calculate the hash of a collection of bytes.\n    pub fn hash_buffer(buffer: &[u8]) -> u32 {\n        let mut a:u16 = 0;\n        let mut b:u16 = 0;\n        for byte in buffer {\n            a = a.wrapping_add(*byte as u16);\n            b = b.wrapping_add(a);\n\n        }\n        (b as u32) << 16 | a as u32\n    }\n}"],"string_diff::EditDistance":["impl OperationScore for EditDistance {\n    #[inline]\n    fn insert_score(&self, _: char) -> i32 {\n        -1\n    }\n\n    #[inline]\n    fn delete_score(&self, _: char) -> i32 {\n        -1\n    }\n\n    #[inline]\n    fn substitution_score(&self, _: char, _: char) -> i32 {\n        -2\n    }\n\n    #[inline]\n    fn match_score(&self, _: char) -> i32 {\n        0\n    }\n}"]},"single_path_import":{},"srcs":{"<Delete as std::fmt::Debug>::fmt":["fn fmt(&self, fmt: &mut fmt::Formatter) -> fmt::Result{\n        write!(fmt, \"Delete({}, {})\", self.position, self.len)\n    }","Real(LocalPath(\"src/lib.rs\"))"],"<Insert as std::fmt::Debug>::fmt":["fn fmt(&self, fmt: &mut fmt::Formatter) -> fmt::Result{\n        write!(fmt, \"Insert({}, '{}')\", self.position, String::from_utf8_lossy(&self.data).replace('\\r', \"\").replace('\\n', \"\\\\n\"))\n    }","Real(LocalPath(\"src/lib.rs\"))"],"<string_diff::EditDistance as string_diff::OperationScore>::delete_score":["#[inline]\nfn delete_score(&self, _: char) -> i32{\n        -1\n    }","Real(LocalPath(\"src/string_diff.rs\"))"],"<string_diff::EditDistance as string_diff::OperationScore>::insert_score":["#[inline]\nfn insert_score(&self, _: char) -> i32{\n        -1\n    }","Real(LocalPath(\"src/string_diff.rs\"))"],"<string_diff::EditDistance as string_diff::OperationScore>::match_score":["#[inline]\nfn match_score(&self, _: char) -> i32{\n        0\n    }","Real(LocalPath(\"src/string_diff.rs\"))"],"<string_diff::EditDistance as string_diff::OperationScore>::substitution_score":["#[inline]\nfn substitution_score(&self, _: char, _: char) -> i32{\n        -2\n    }","Real(LocalPath(\"src/string_diff.rs\"))"],"BlockHashes":["/// Used for calculating and re-calculating the differences between two versions of the same file\n///\n/// See the [module level documentation](index.html) for examples on how to use this\npub struct BlockHashes {\n    hashes: HashMap<u32, Vec<(usize, [u8; 16])>>,\n    block_size: usize,\n    file_size: usize\n}","Real(LocalPath(\"src/lib.rs\"))"],"Delete":["/// Represents an operation to delete a certain number of bytes at a particular position in a file\npub struct Delete {\n    position: usize,\n    len: usize\n}","Real(LocalPath(\"src/lib.rs\"))"],"Delete::compress_to":["/// Compress this operation and write to `writer`.  The output can then be expanded\n/// back into an equivilent operation using `expand_from()`\npub fn compress_to<W: Write>(&self, writer: &mut W) -> io::Result<()>{\n\n        let mut int_buf = [0;4];\n        NetworkEndian::write_u32(&mut int_buf, self.position as u32);\n        try!(writer.write(&int_buf));\n        NetworkEndian::write_u32(&mut int_buf, self.len as u32);\n        try!(writer.write(&int_buf));\n        Ok(())\n    }","Real(LocalPath(\"src/lib.rs\"))"],"Delete::expand_from":["/// Expand this operation from previously compressed data in `reader`.  The data in reader\n/// should have been written using `compress_to()`\npub fn expand_from<R: Read>(reader: &mut R) -> io::Result<Delete>{\n        let mut int_buf = [0;4];\n        try!(reader.read_exact(&mut int_buf));\n        let position = NetworkEndian::read_u32(&int_buf);\n        try!(reader.read_exact(&mut int_buf));\n        let len = NetworkEndian::read_u32(&int_buf);\n        Ok(Delete{\n            position: position as usize,\n            len: len as usize,\n        })\n    }","Real(LocalPath(\"src/lib.rs\"))"],"Delete::get_length":["/// Gets the length in bytes of this delete operation\n#[inline]\npub fn get_length(&self) -> usize{\n        self.len\n    }","Real(LocalPath(\"src/lib.rs\"))"],"Delete::get_position":["/// Gets the byte position of this delete operation in its file\n#[inline]\npub fn get_position(&self) -> usize{\n        self.position\n    }","Real(LocalPath(\"src/lib.rs\"))"],"Diff":["/// Represents a series of operations that were performed on a file to transform it into a new\n/// version.\n///\n/// The operations are stored in file order, which means that every operation that affects\n/// an earlier part of the file must be stored before an operation that affects a later part.\n/// The diff also assumes that insert operations are performed prior to delete operations.\npub struct Diff {\n    inserts: Vec<Insert>,\n    deletes: Vec<Delete>\n}","Real(LocalPath(\"src/lib.rs\"))"],"Diff::add_delete":["/// all previously added insert and delete operations in file order.  If the operation\n/// can be merged with the previous operation, then it is.\nfn add_delete(&mut self, position: usize, len: usize){\n        if let Some(tail) = self.deletes.last_mut() {\n            if tail.position  == position {\n                tail.len += len;\n                return;\n            }\n        }\n        self.deletes.push(Delete {\n            position: position,\n            len: len\n        });\n    }","Real(LocalPath(\"src/lib.rs\"))"],"Diff::add_insert":["/// Adds an insert operation into this diff.  The operation must occur after\n/// all previously added insert operations in file order.  If the operation\n/// can be merged with the previous operation, then it is.\n///\n/// Consumes the data that is passed in\nfn add_insert(&mut self, position: usize, mut data: Vec<u8>){\n        if let Some(tail) = self.inserts.last_mut() {\n            if tail.position + tail.data.len() == position {\n                tail.data.append(&mut data);\n                return;\n            }\n        }\n        self.inserts.push(Insert {\n            position: position,\n            data: data\n        });\n    }","Real(LocalPath(\"src/lib.rs\"))"],"Diff::apply":["/// Apply the operations in this sequence to a file.  This should not be called until after\n/// the sequence has been integrated via [`Engine::integrate_remote`](struct.Engine.html#method.integrate_remote)\n/// The file must have been opened on both read and write mode (see [OpenOptions](https://doc.rust-lang.org/nightly/std/fs/struct.OpenOptions.html)).\npub fn apply(&self, file: &mut File) -> io::Result<()>{\n        let mut new_bytes = Vec::new();\n        try!(file.seek(SeekFrom::Start(0)));\n        let mut old_bytes = file.try_clone().unwrap().bytes();\n        let mut index = 0;\n        for insert in self.inserts.iter() {\n            while index < insert.position {\n                new_bytes.push(try!(old_bytes.next().unwrap()).clone());\n                index += 1;\n            }\n            new_bytes.extend_from_slice(&insert.data[..]);\n            index += insert.data.len();\n        }\n        while let Some(byte) = old_bytes.next() {\n            new_bytes.push(try!(byte));\n        }\n        let old_bytes = mem::replace(&mut new_bytes, Vec::new());\n        let mut old_bytes = old_bytes.into_iter();\n        index = 0;\n        for delete in self.deletes.iter() {\n            while index < delete.position {\n                new_bytes.push(old_bytes.next().unwrap());\n                index += 1;\n            }\n            for _ in 0..delete.len {\n                old_bytes.next();\n            }\n        }\n        while let Some(byte) = old_bytes.next() {\n            new_bytes.push(byte);\n        }\n\n        try!(file.seek(SeekFrom::Start(0)));\n        try!(file.set_len(new_bytes.len() as u64));\n        file.write_all(new_bytes.as_slice())\n    }","Real(LocalPath(\"src/lib.rs\"))"],"Diff::apply_to_string":["/// Applies all of the operations in the diff to the given string.\n/// Gives an error if the resulting string can't be represented by utf8.\n///\n/// # Panics\n/// When the operations refer to positions that are not represented by the string.\npub fn apply_to_string(&self, string: &str) -> Result<String, FromUtf8Error>{\n        let mut old_bytes = string.bytes();\n        let mut new_bytes = Vec::new();\n        let mut index = 0;\n        for insert in self.inserts() {\n            while index < insert.position {\n                new_bytes.push(old_bytes.next().unwrap().clone());\n                index += 1;\n            }\n            new_bytes.append(&mut insert.data.clone());\n            index += insert.data.len();\n        }\n        while let Some(byte) = old_bytes.next() {\n            new_bytes.push(byte);\n        }\n        let old_bytes = mem::replace(&mut new_bytes, Vec::new());\n        let mut  old_bytes = old_bytes.into_iter();\n        index = 0;\n        for delete in self.deletes() {\n            while index < delete.position {\n                new_bytes.push(old_bytes.next().unwrap());\n                index += 1;\n            }\n            for _ in 0..delete.len {\n                old_bytes.next();\n            }\n        }\n        while let Some(byte) = old_bytes.next() {\n            new_bytes.push(byte);\n        }\n        String::from_utf8(new_bytes)\n    }","Real(LocalPath(\"src/lib.rs\"))"],"Diff::compress_to":["/// Compress this diff and write to `writer`.  The output can then be expanded\n/// back into an equivilent Diff using `expand_from()`\npub fn compress_to<W: Write>(&self, writer: &mut W) -> io::Result<()>{\n\n        let mut int_buf = [0;4];\n        NetworkEndian::write_u32(&mut int_buf, self.inserts.len() as u32);\n        try!(writer.write(&mut int_buf));\n        for insert in self.inserts.iter() {\n            try!(insert.compress_to(writer));\n        }\n        NetworkEndian::write_u32(&mut int_buf, self.deletes.len() as u32);\n        try!(writer.write(&mut int_buf));\n        for delete in self.deletes.iter() {\n            try!(delete.compress_to(writer));\n        }\n        Ok(())\n    }","Real(LocalPath(\"src/lib.rs\"))"],"Diff::deletes":["/// Gets an iterator over all delete operations\npub fn deletes(&self) -> Iter<Delete>{\n        self.deletes.iter()\n    }","Real(LocalPath(\"src/lib.rs\"))"],"Diff::expand_from":["/// Expand this diff from previously compressed data in `reader`.  The data in reader\n/// should have been written using `compress_to()`\npub fn expand_from<R: Read>(reader: &mut R) -> io::Result<Diff>{\n        let mut int_buf = [0;4];\n\n        trace!(\"Reading insert length\");\n        try!(reader.read_exact(&mut int_buf));\n        let insert_len = NetworkEndian::read_u32(&int_buf);\n        trace!(\"Insert length was: {}\", insert_len);\n        let inserts = (0..insert_len).map(|_|Insert::expand_from(reader).unwrap()).collect();\n        trace!(\"Read inserts\");\n        trace!(\"Reading delete length\");\n        try!(reader.read_exact(&mut int_buf));\n        let delete_len = NetworkEndian::read_u32(&int_buf);\n        trace!(\"Delete length was: {}\", delete_len);\n        let deletes = (0..delete_len).map(|_|Delete::expand_from(reader).unwrap()).collect();\n        trace!(\"Read deletes\");\n        Ok(Diff {\n            inserts: inserts,\n            deletes: deletes\n        })\n    }","Real(LocalPath(\"src/lib.rs\"))"],"Diff::inserts":["/// Gets an iterator over all insert operations\npub fn inserts(&self) -> Iter<Insert>{\n        self.inserts.iter()\n    }","Real(LocalPath(\"src/lib.rs\"))"],"Diff::is_empty":["/// Checks if this set of diffs has any actual content\npub fn is_empty(&self) -> bool{\n        self.deletes.is_empty() && self.inserts.is_empty()\n    }","Real(LocalPath(\"src/lib.rs\"))"],"Diff::new":["/// Creates a new `Diff`\n#[inline]\npub fn new() -> Diff{\n        Diff {\n            inserts: Vec::new(),\n            deletes: Vec::new()\n        }\n    }","Real(LocalPath(\"src/lib.rs\"))"],"Insert":["/// Represents an operation to insert bytes at a particular position into a file\npub struct Insert {\n    position: usize,\n    data: Vec<u8>\n}","Real(LocalPath(\"src/lib.rs\"))"],"Insert::compress_to":["/// Compress this operation and write to `writer`.  The output can then be expanded\n/// back into an equivilent operation using `expand_from()`\npub fn compress_to<W: Write>(&self, writer: &mut W) -> io::Result<()>{\n\n        let mut int_buf = [0;4];\n        NetworkEndian::write_u32(&mut int_buf, self.position as u32);\n        try!(writer.write(&int_buf));\n        NetworkEndian::write_u32(&mut int_buf, self.data.len() as u32);\n        try!(writer.write(&int_buf));\n        try!(writer.write(&self.data));\n        Ok(())\n    }","Real(LocalPath(\"src/lib.rs\"))"],"Insert::expand_from":["/// Expand this operation from previously compressed data in `reader`.  The data in reader\n/// should have been written using `compress_to()`\npub fn expand_from<R: Read>(reader: &mut R) -> io::Result<Insert>{\n        let mut int_buf = [0;4];\n        try!(reader.read_exact(&mut int_buf));\n        let position = NetworkEndian::read_u32(&int_buf);\n        try!(reader.read_exact(&mut int_buf));\n        let data_len = NetworkEndian::read_u32(&int_buf) as usize;\n        let mut data = Vec::with_capacity(data_len);\n        data.resize(data_len, 0);\n        try!(reader.read_exact(&mut data));\n        Ok(Insert{\n            position: position as usize,\n            data: data\n        })\n    }","Real(LocalPath(\"src/lib.rs\"))"],"Insert::get_data":["/// Gets the data this insert operation will insert\n#[inline]\npub fn get_data(&self) -> &Vec<u8>{\n        &self.data\n    }","Real(LocalPath(\"src/lib.rs\"))"],"Insert::get_position":["/// Gets the byte position of this insert operation in its file\n#[inline]\npub fn get_position(&self) -> usize{\n        self.position\n    }","Real(LocalPath(\"src/lib.rs\"))"],"Window":["/// A sliding window over a reader.  This monatins an internal buffer read from the file,\n/// which can be read from at any time.\nstruct Window<R: Read> {\n    front: Vec<u8>,\n    back: Vec<u8>,\n    block_size: usize,\n    offset: usize,\n    bytes_read: usize,\n    reader: R\n}","Real(LocalPath(\"src/lib.rs\"))"],"hashing::<impl BlockHashes>::check_match":["/// Checks if the current window frame matches any existing block with an index greater than the previously matched block.\n///\n/// Returns the index of the matching block if it does\nfn check_match<R: Read>(&self, weak_hasher: &RollingHash, mut strong_hasher: &mut Md5, mut window: &Window<R>, last_matching_block_index: &mut i32) -> Option<usize>{\n        if let Some(other_block_index) = self.hash_match(&weak_hasher, &mut strong_hasher, &mut window) {\n            if other_block_index as i32 > *last_matching_block_index {\n                return Some(other_block_index);\n            }\n        }\n        None\n    }","Real(LocalPath(\"src/hashing.rs\"))"],"hashing::<impl BlockHashes>::compress_to":["/// Compress these Hashes and write to `writer`.  The output can then be expanded\n/// back into an equivilent Hash collection using `expand_from()`\npub fn compress_to<W: Write>(&self, writer: &mut W) -> Result<()>{\n\n        let mut int_buf = [0;4];\n        NetworkEndian::write_u32(&mut int_buf, self.file_size as u32);\n        try!(writer.write(&int_buf));\n        NetworkEndian::write_u32(&mut int_buf, self.block_size as u32);\n        try!(writer.write(&int_buf));\n        let block_count = (self.file_size + self.block_size - 1) / self.block_size;\n        let dummy_hash = [0u8;16];\n        let mut sequential_hashes = Vec::with_capacity(block_count);\n        sequential_hashes.resize(block_count, (0, &dummy_hash));\n        for (weak_hash, entry) in self.hashes.iter() {\n            for &(index, ref strong_hash) in entry.iter() {\n                sequential_hashes[index] = (*weak_hash, strong_hash);\n            }\n        }\n        for (weak, strong) in sequential_hashes {\n            NetworkEndian::write_u32(&mut int_buf, weak);\n            try!(writer.write(&int_buf));\n            try!(writer.write(strong));\n        }\n        Ok(())\n    }","Real(LocalPath(\"src/hashing.rs\"))"],"hashing::<impl BlockHashes>::diff_and_update":["/// Compare the data in `new_data` with the hashes computed from either\n/// the most recent call to `diff_and_update()` or when this `BlockHashes` was updated\n///\n/// # Example\n///\n/// ```\n/// use rdiff::BlockHashes;\n/// use std::io::Cursor;\n/// let mut hashes = BlockHashes::new(Cursor::new(\"It was the best of times\"), 6).unwrap();\n/// let diff = hashes.diff_and_update(Cursor::new(\"It was not the best of things\")).unwrap();\n/// // prints (6, ' not') and (22, ' things'))\n/// for insert in diff.inserts() {\n///     println!(\"{:?}\", insert);\n/// }\n/// // prints (29, 6)\n/// for delete in diff.deletes() {\n///     println!(\"{:?}\", delete);\n/// }\n/// assert_eq!(\"It was not the best of things\",\n///             diff.apply_to_string(\"It was the best of times\").unwrap());\n/// ```\npub fn diff_and_update<R: Read>(&mut self, new_data: R) -> Result<Diff>{\n        use std::mem;\n        let mut diffs = Diff::new();\n        let mut window = try!(Window::new(new_data, self.block_size));\n        let mut weak_hasher = RollingHash::new(window.frame().0.iter());\n        let mut strong_hasher = Md5::new();\n        let mut last_matching_block_index = -1;\n        let mut insert_buffer = Vec::new();\n        let mut new_hashes = HashMap::new();\n        let mut current_block_index = 0;\n        while window.frame_size() > 0 {\n\n            if let Some(other_block_index) = self.check_match(&weak_hasher, &mut strong_hasher, &mut window, &mut last_matching_block_index) {\n                //create an insert if the insert buffer has anything in it\n                if insert_buffer.len() > 0 {\n                    // XXX with some work here, we could probably track the insert buffer as a piece of the window, which is then\n                    // moved into the diff list.\n                    diffs.add_insert(window.get_bytes_read() - insert_buffer.len(), mem::replace(&mut insert_buffer, Vec::new()));\n                }\n                //create a delete if the index is more than it should be\n                if other_block_index as i32 > last_matching_block_index + 1 {\n                    diffs.add_delete(window.get_bytes_read(), self.block_size * (other_block_index as i32 - last_matching_block_index - 1) as usize)\n                }\n                last_matching_block_index = other_block_index as i32;\n                //advance forward an entire block's worth\n                for i in 0..self.block_size {\n                    if window.on_boundry() {\n                        // This might iterate past the end of the data.  If so, bail out\n                        if window.frame_size() == 0 {\n                            break;\n                        }\n                        let mut strong_hash:[u8;16] = [0;16];\n                        // If the boundry happened where we saw a match, we can skip the\n                        // strong hashing, because it was already done during the\n                        // match checking\n                        if i != 0 {\n                            let (front, back) = window.frame();\n                            strong_hasher.reset();\n                            strong_hasher.input(front);\n                            strong_hasher.input(back);\n                        }\n                        strong_hasher.result(&mut strong_hash);\n\n                        new_hashes.entry(weak_hasher.get_hash()).or_insert(Vec::new()).push((current_block_index, strong_hash));\n                        current_block_index += 1;\n                    }\n                    let (tail, head) = try!(window.advance());\n                    if let Some(tail) = tail {\n                        weak_hasher.roll_hash(head, tail);\n                    } else {\n                        break;\n                    }\n                }\n            } else {\n                //advance forward one byte\n                if window.on_boundry() {\n                    // XXX There is a slight optimization possible here, where\n                    // when the weak checksum matches, but the strong one doesn't\n                    // we are re-computing the strong checksum here.\n                    let mut strong_hash:[u8;16] = [0;16];\n                    let (front, back) = window.frame();\n                    strong_hasher.reset();\n                    strong_hasher.input(front);\n                    strong_hasher.input(back);\n                    strong_hasher.result(&mut strong_hash);\n\n                    new_hashes.entry(weak_hasher.get_hash()).or_insert(Vec::new()).push((current_block_index, strong_hash));\n                    current_block_index += 1;\n                }\n                let (tail, head) = try!(window.advance());\n                weak_hasher.roll_hash(head, tail.unwrap());\n                insert_buffer.push(tail.unwrap());\n            }\n        }\n        if insert_buffer.len() > 0 {\n            diffs.add_insert(window.get_bytes_read() - insert_buffer.len(), insert_buffer);\n        }\n        let old_block_count = (self.file_size + self.block_size - 1) as i32 / self.block_size as i32;\n        if last_matching_block_index + 1 < old_block_count {\n            diffs.add_delete(window.get_bytes_read(), (self.file_size as i32 - (last_matching_block_index + 1) * self.block_size as i32) as usize);\n        }\n        self.hashes = new_hashes;\n        self.file_size = window.get_bytes_read();\n        Ok(diffs)\n    }","Real(LocalPath(\"src/hashing.rs\"))"],"hashing::<impl BlockHashes>::empty":["/// Construct a new block hash for a file that was just created\npub fn empty(block_size: usize) -> BlockHashes{\n        BlockHashes {\n            hashes: HashMap::new(),\n            block_size: block_size,\n            file_size: 0\n        }\n    }","Real(LocalPath(\"src/hashing.rs\"))"],"hashing::<impl BlockHashes>::expand_from":["/// Expand these hashes from previously compressed data in `reader`.  The data in reader\n/// should have been written using `compress_to()`\npub fn expand_from<R: Read>(reader: &mut R) -> Result<BlockHashes>{\n        let mut int_buf = [0;4];\n        let mut strong_hash = [0u8;16];\n        try!(reader.read(&mut int_buf));\n        let file_size = NetworkEndian::read_u32(&mut int_buf) as usize;\n        try!(reader.read(&mut int_buf));\n        let block_size = NetworkEndian::read_u32(&mut int_buf) as usize;\n        let block_count = (file_size + block_size - 1) / block_size;\n        // Might be an overestimate, but not by more than a few\n        let mut hashes = HashMap::with_capacity(block_count);\n\n        for block_index in 0..block_count {\n            try!(reader.read(&mut int_buf));\n            let weak_hash = NetworkEndian::read_u32(&mut int_buf);\n            try!(reader.read(&mut strong_hash));\n            hashes.entry(weak_hash).or_insert(Vec::new()).push((block_index, strong_hash));\n        }\n        Ok(BlockHashes {\n            file_size: file_size,\n            block_size: block_size,\n            hashes: hashes\n        })\n    }","Real(LocalPath(\"src/hashing.rs\"))"],"hashing::<impl BlockHashes>::hash_match":["/// Checks to see if the hash of the current window frame matches an existing hash.\n///\n/// If so, returns the index of the matching block\nfn hash_match<R: Read>(&self, weak_hasher: &RollingHash,  strong_hasher: &mut Md5, window: &Window<R>) -> Option<usize>{\n        let mut new_result = [0;16];\n        if let Some(matches) = self.hashes.get(&weak_hasher.get_hash()) {\n            for &(index, strong_hash) in matches.iter() {\n                strong_hasher.reset();\n                let (front, back) = window.frame();\n                strong_hasher.input(front);\n                strong_hasher.input(back);\n                strong_hasher.result(&mut new_result);\n                if new_result == strong_hash {\n                    return Some(index)\n                }\n            }\n        }\n        return None\n    }","Real(LocalPath(\"src/hashing.rs\"))"],"hashing::<impl BlockHashes>::new":["/// Create a new BlockHash based on the data in data_source.  This method\n/// will create a hash for every `block_size` set of bytes in `data_source`.\n///\n/// To see the difference after `data_source` has been updated, use `diff_and_update()`\n///\n/// This method returns an error when there is a problem reading from `data_source`.\npub fn new<R: Read>(mut data_source: R, block_size: usize) -> Result<BlockHashes>{\n        let mut block = vec![0;block_size];\n        let mut hashes = HashMap::new();\n        let mut block_index = 0;\n        let mut strong_hasher = Md5::new();\n        let mut total_size = 0;\n\n        let mut read_size = try!(data_source.read(&mut block));\n        while read_size > 0 {\n            let weak_hash = RollingHash::hash_buffer(&block[..read_size]);\n\n            let mut strong_hash:[u8;16] = [0;16];\n            strong_hasher.reset();\n            strong_hasher.input(&block[..read_size]);\n            strong_hasher.result(&mut strong_hash);\n\n            hashes.entry(weak_hash).or_insert(Vec::new()).push((block_index, strong_hash));\n\n            block_index += 1;\n            total_size += read_size;\n            read_size = try!(data_source.read(&mut block));\n        }\n        Ok(BlockHashes {\n            hashes: hashes,\n            block_size: block_size,\n            file_size: total_size\n        })\n    }","Real(LocalPath(\"src/hashing.rs\"))"],"hashing::<impl BlockHashes>::verify_unchanged":["/// Checks if `data_source` has changed since the last time the hashes were updated.\n///\n/// Returns true if `data_source` is identical to what it was when the hashes were generated, false otherwise\npub fn verify_unchanged<R: Read>(&self, data_source: &mut R) -> Result<bool>{\n        let mut block = vec![0;self.block_size];\n        let mut block_index = 0;\n        let mut strong_hasher = Md5::new();\n        let mut total_size = 0;\n\n        let mut read_size = try!(data_source.read(&mut block));\n        while read_size > 0 {\n            let weak_hash = RollingHash::hash_buffer(&block[..read_size]);\n            if let Some(entry) = self.hashes.get(&weak_hash) {\n                let mut strong_hash:[u8;16] = [0;16];\n                strong_hasher.reset();\n                strong_hasher.input(&block[..read_size]);\n                strong_hasher.result(&mut strong_hash);\n                if !entry.contains(&(block_index, strong_hash)) {\n                    return Ok(false);\n                }\n            }\n\n\n            block_index += 1;\n            total_size += read_size;\n            read_size = try!(data_source.read(&mut block));\n        }\n        Ok(total_size == self.file_size)\n    }","Real(LocalPath(\"src/hashing.rs\"))"],"hashing::RollingHash":["/// Implements a weak, but easy to calculate hash for a block of bytes\n///\n/// The hash is comprised of two bytes.  The first is the sum of the bytes\nstruct RollingHash {\n    a: u16,\n    b: u16,\n    block_size: u16\n}","Real(LocalPath(\"src/hashing.rs\"))"],"hashing::RollingHash::get_hash":["/// Gets the hash as it currently stands\npub fn get_hash(&self) -> u32{\n        return (self.b as u32) << 16 | self.a as u32;\n    }","Real(LocalPath(\"src/hashing.rs\"))"],"hashing::RollingHash::hash_buffer":["/// Calculate the hash of a collection of bytes.\npub fn hash_buffer(buffer: &[u8]) -> u32{\n        let mut a:u16 = 0;\n        let mut b:u16 = 0;\n        for byte in buffer {\n            a = a.wrapping_add(*byte as u16);\n            b = b.wrapping_add(a);\n\n        }\n        (b as u32) << 16 | a as u32\n    }","Real(LocalPath(\"src/hashing.rs\"))"],"hashing::RollingHash::new":["/// Creates a new rolling hash over the bytes in `initial_data`.\n/// It will be assumed that the size of blocks will be the size of the initial data.\npub fn new<'a, I: Iterator<Item=&'a u8>>(initial_data: I) -> RollingHash{\n\n        let mut a:u16 = 0;\n        let mut b:u16 = 0;\n        let mut block_size: u16 = 0;\n        for byte in initial_data {\n            a = a.wrapping_add(*byte as u16);\n            b = b.wrapping_add(a);\n            block_size += 1;\n        }\n        RollingHash {\n            a: a,\n            b: b,\n            block_size: block_size\n        }\n    }","Real(LocalPath(\"src/hashing.rs\"))"],"hashing::RollingHash::roll_hash":["/// Roll the has forward one byte.  This function will remove `old_byte` from its calculation\n/// and add `new_byte` if it exists.\n/// To get the hash afterwards, use `get_hash()`.\npub fn roll_hash(&mut self, new_byte: Option<u8>, old_byte: u8){\n        self.a = self.a.wrapping_sub(old_byte as u16);\n        self.b = self.b.wrapping_sub(((old_byte as u16).wrapping_mul(self.block_size as u16)) as u16);\n        if let Some(new_byte) = new_byte {\n            self.a = self.a.wrapping_add(new_byte as u16);\n            self.b = self.b.wrapping_add(self.a);\n        } else {\n            self.block_size -= 1\n        }\n    }","Real(LocalPath(\"src/hashing.rs\"))"],"string_diff::EditDistance":["/// Used as the classiscal definition of edit distance.\n///\n/// That is:\n///\n/// * Insert is cost -1\n/// * Delete is cost -1\n/// * Substitution is cost -2 (an insert + a delete)\n/// * Matching is cost 0\npub struct EditDistance;","Real(LocalPath(\"src/string_diff.rs\"))"],"string_diff::OperationScore":["/// Used to calculate the score for each operation that\n/// will be performed.  The score can be static, or it can\n/// vary based on which character is being deleted inserted or substituted.\n/// It is highly recommended to inline the implementation of these characters\npub trait OperationScore {\n    /// The score for inserting character `c` into the string\n    fn insert_score(&self, c: char) -> i32;\n    /// The score for deleting character `c` from the string\n    fn delete_score(&self, c: char) -> i32;\n    /// The score for replacing character `old` with character `new`\n    fn substitution_score(&self, old: char, new: char) -> i32;\n    /// The score for when a character is one string matches the character in the other string\n    fn match_score(&self, c: char) -> i32;\n}","Real(LocalPath(\"src/string_diff.rs\"))"],"string_diff::find_diff":["/// Finds the difference on a character by character level between two strings\n///\n/// Uses the Hirschberg algorithm (doi: [10.1145/360825.360861](http://dx.doi.org/10.1145/360825.360861))\n/// which operates in `O(x * y)` time and `O(y)` space.  The algorithm finds the minimal set of operations\n/// that will transform 'old' into 'new'.  The 'weight' of each operation is determined by the `scorer.`\n/// For more details about weighting, see the [OperationScore](trait.OperationScore.html) documentation.\n///\n/// The operations in the returned `Diff `are presented in file order, with offsets assuming the\n/// previous operations have already been performed.  Furthermore, the inserts are assumed to\n/// be performed prior to the deletes.\n///\n/// # Example\n///\n/// ```\n/// use rdiff::string_diff::{find_diff, EditDistance};\n/// // Find the difference between meadow and yellowing using the edit distance as the weighting.\n/// let diff = find_diff(\"meadow\", \"yellowing\", &EditDistance{});\n/// // prints (0, 'y'), (3, 'll') and (9, 'ing')\n/// for insert in diff.inserts() {\n///     println!(\"{:?}\", insert);\n/// }\n/// // prints (1, 1) and (4, 2)\n/// for delete in diff.deletes() {\n///     println!(\"{:?}\", delete);\n/// }\n/// assert_eq!(\"yellowing\", diff.apply_to_string(\"meadow\").unwrap());\n/// ```\npub fn find_diff<S: OperationScore>(old: &str, new: &str, scorer: &S) -> Diff{\n    let mut diff = Diff::new();\n    let mut insert_index = 0;\n    let mut delete_index = 0;\n    let old_rev = old.chars().rev().collect::<String>();\n    let new_rev = new.chars().rev().collect::<String>();\n    hirschberg(old, new, &old_rev, &new_rev, scorer, &mut diff, &mut insert_index, &mut delete_index);\n    diff\n}","Real(LocalPath(\"src/string_diff.rs\"))"],"string_diff::hirschberg":["/// Uses the Hirschberg algorithm to calculate the optimal set of operations to transform 'old' into 'new'.\n/// The only parameters that are input are 'old', 'new' and `scorer`.  `x_rev` and `y_rev` are just\n/// cached so that 'old' and 'new' don't need to be reversed for every recursion of the algorithm.\n/// `diff` is the output of the algorithm and `insert_index` and `delete_index` are simply intermediate state\n/// being passed around.\nfn hirschberg<S: OperationScore>(old: &str, new: &str, old_rev: &str, new_rev: &str, scorer: &S, diff: &mut Diff, insert_index: &mut usize, delete_index: &mut usize){\n    trace!(\"'{}' ({}) '{}' ({})\", old, old_rev, new, new_rev);\n    // We're going to use these lengths over and over again, we might as well cache them.\n    let old_len = old.len();\n    let new_len = new.len();\n\n    // If one of the two strings is 0, then it's trvial to transform one into the other\n    if old_len == 0 {\n        do_insert!(new, insert_index, diff);\n    } else if new_len == 0 {\n        do_delete!(old_len, delete_index, insert_index, diff);\n    }\n    // If old is legnth 1, then there are two cases:\n    else if old_len == 1 {\n        let old_char = old.chars().next().unwrap();\n        match new.chars().position(|c| c == old_char) {\n            // Either new contains old, in which case\n            Some(position) => {\n                // We insert whatever is on the left of old in new\n                if position > 0 {\n                    do_insert!(new[..position], insert_index, diff);\n                }\n                *insert_index += 1;\n                // and we insert whatever is on the right of old in new\n                if new_len - position > 1 {\n                    do_insert!(new[position + 1..], insert_index, diff);\n                }\n            } None => {\n                //or new does not contain old, in which case\n                // we simply delete old and insert new\n                do_insert!(new, insert_index, diff);\n                do_delete!(1, delete_index, insert_index, diff);\n            }\n        }\n    }\n    // If new is length 1, then there are two cases:\n    else if new_len == 1 {\n        let new_char = new.chars().next().unwrap();\n        match old.chars().position(|c| c == new_char) {\n            // either old contains new, in which case\n            Some(position) => {\n                // We delete everything in old to the left of new\n                if position > 0 {\n                    do_delete!(position, delete_index, insert_index, diff);\n                }\n                *insert_index += 1;\n                // and we delete everything in old to the right of new\n                if old_len - position > 1 {\n                    let delete_len = old_len - position - 1;\n                    do_delete!(delete_len, delete_index, insert_index, diff);\n                }\n            } None => {\n                // or old does not contain new, in which case we simply insert new and delete\n                // everything that was previously in old\n                do_insert!(new, insert_index, diff);\n                do_delete!(old_len, delete_index, insert_index, diff);\n            }\n        }\n    } else {\n        // If it's not trivial, then we recurse until it is.\n        // We begin bnew dividing old in half.\n        let old_mid = old_len / 2;\n        // We then find the index in new where splitting the string will give us the\n        // highest possible score.  This index is the point where the trace of the edit\n        // operations performed is guaranteed to cross.\n        let score_l = nw_score(&old[..old_mid], new, scorer);\n        let score_r = nw_score(&old_rev[..old_len - old_mid], new_rev, scorer);\n        let new_mid = score_l.iter()\n                            .zip(score_r.iter().rev())\n                            .map(|(l, r)| l + r)\n                            .zip(0..new_len + 1).max().unwrap().1;\n        // We then recurse on the left side of old and new\n        hirschberg(&old[..old_mid], &new[..new_mid], &old_rev[old_len - old_mid..], &new_rev[new_len - new_mid..], scorer, diff, insert_index, delete_index);\n        // and the right side of old and new\n        hirschberg(&old[old_mid..], &new[new_mid..], &old_rev[..old_len - old_mid], &new_rev[..new_len - new_mid], scorer, diff, insert_index, delete_index);\n\n\n    }\n\n}","Real(LocalPath(\"src/string_diff.rs\"))"],"string_diff::nw_score":["/// Calculate the score based on the Needleman-Wunsch algorithm.  This algorithm\n/// calculates the cost of transforming string 'old' into string 'new' using operation scoring\n/// given by `scorer`.\n///\n/// It operates by iteratively generating the score for progressively longer\n/// substrings of 'old' and 'new'.  The result is a vector of the transformation score\n/// from 'old' to a substring of length `i` of 'new' where `i` is the index of an element in\n/// the resulting vector.\nfn nw_score<S: OperationScore>(old: &str, new: &str, scorer: &S) -> Vec<i32>{\n\n    trace!(\"nw_score for '{}' - '{}'\", old, new);\n    let row_len = new.len() + 1;\n    let mut last_row = Vec::with_capacity(row_len);\n    let mut this_row = Vec::with_capacity(row_len);\n    let mut total_insert = 0;\n    last_row.push(0);\n    for new_char in new.chars() {\n        total_insert += scorer.insert_score(new_char);\n        last_row.push(total_insert);\n    }\n    trace!(\"{:?}\", last_row);\n    for old_char in old.chars() {\n        this_row.push(last_row[0] + scorer.delete_score(old_char));\n        for (new_index, new_char) in new.chars().enumerate() {\n            let score_sub = last_row[new_index] + if old_char == new_char {\n                scorer.match_score(old_char)\n            } else {\n                scorer.substitution_score(old_char, new_char)\n            };\n            let score_del = last_row[new_index + 1] + scorer.delete_score(old_char);\n            let score_ins = this_row[new_index] + scorer.insert_score(new_char);\n            this_row.push(max(max(score_sub, score_del), score_ins))\n        }\n        trace!(\"{:?}\", this_row);\n        last_row = mem::replace(&mut this_row, Vec::with_capacity(row_len));\n    }\n    last_row\n\n}","Real(LocalPath(\"src/string_diff.rs\"))"],"window::<impl Window<R>>::advance":["pub fn advance(&mut self) -> Result<(Option<u8>, Option<u8>)>{\n        if self.front.len() == 0 {\n            return Ok((None, None));\n        }\n\n        if self.offset >= self.front.len() {\n            if self.back.len() == 0 {\n                return Ok((None, None));\n            }\n            try!(self.load_next_block());\n        }\n        let tail = self.front[self.offset];\n        let head = self.get_head();\n        self.offset += 1;\n        self.bytes_read += 1;\n        Ok((Some(tail), head))\n    }","Real(LocalPath(\"src/window.rs\"))"],"window::<impl Window<R>>::frame":["pub fn frame<'a>(&'a self) -> (&'a [u8], &'a [u8]){\n        let front_offset = min(self.offset, self.front.len());\n        let back_offset = min(self.offset, self.back.len());\n        (&self.front[front_offset..], &self.back[..back_offset])\n    }","Real(LocalPath(\"src/window.rs\"))"],"window::<impl Window<R>>::frame_size":["pub fn frame_size(&self) -> usize{\n        self.front.len() + self.back.len() - self.offset\n    }","Real(LocalPath(\"src/window.rs\"))"],"window::<impl Window<R>>::get_bytes_read":["pub fn get_bytes_read(&self) -> usize{\n        self.bytes_read\n    }","Real(LocalPath(\"src/window.rs\"))"],"window::<impl Window<R>>::get_head":["fn get_head(&self) -> Option<u8>{\n        let head_index = self.offset + self.block_size - self.front.len();\n        if head_index >= self.back.len() {\n            return None;\n        }\n        return Some(self.back[head_index]);\n    }","Real(LocalPath(\"src/window.rs\"))"],"window::<impl Window<R>>::load_next_block":["fn load_next_block(&mut self) -> Result<()>{\n        // We've gone past the end of the front half\n        self.front = mem::replace(&mut self.back, vec!(0;self.block_size));\n        let size = try!(self.reader.read(self.back.as_mut_slice()));\n        unsafe{\n            self.back.set_len(size);\n        }\n        self.offset = 0;\n        Ok(())\n    }","Real(LocalPath(\"src/window.rs\"))"],"window::<impl Window<R>>::new":["pub fn new(mut reader:R, block_size: usize) -> Result<Window<R>>{\n        let mut front = vec!(0;block_size);\n        let mut back = vec!(0;block_size);\n        let size = try!(reader.read(front.as_mut_slice()));\n        unsafe {\n            front.set_len(size);\n        }\n        let size = try!(reader.read(back.as_mut_slice()));\n        unsafe {\n            back.set_len(size);\n        }\n        Ok(Window {\n            front: front,\n            back: back,\n            block_size: block_size,\n            offset: 0,\n            reader: reader,\n            bytes_read: 0\n        })\n    }","Real(LocalPath(\"src/window.rs\"))"],"window::<impl Window<R>>::on_boundry":["pub fn on_boundry(&self) -> bool{\n        self.offset == 0 || self.offset == self.front.len()\n    }","Real(LocalPath(\"src/window.rs\"))"]},"struct_constructor":{"(&'a [u8], &'a [u8])":["frame"],"(std::option::Option<u8>, std::option::Option<u8>)":["advance"],"BlockHashes":["empty","expand_from","new"],"Delete":["expand_from"],"Diff":["diff_and_update","expand_from","find_diff","new"],"Insert":["expand_from"],"Window":["new"],"bool":["eq","is_empty","on_boundry","verify_unchanged"],"hashing::RollingHash":["new"],"i32":["delete_score","insert_score","match_score","substitution_score"],"std::slice::Iter":["deletes","inserts"],"std::string::String":["apply_to_string"],"std::vec::Vec":["nw_score"],"u32":["get_hash","hash_buffer"],"u8":["get_head"],"usize":["check_match","frame_size","get_bytes_read","get_length","get_position","hash_match"]},"struct_to_trait":{"BlockHashes":["std::cmp::PartialEq","std::fmt::Debug","std::marker::StructuralPartialEq"],"Delete":["std::cmp::PartialEq","std::fmt::Debug","std::marker::StructuralPartialEq"],"Diff":["std::cmp::PartialEq","std::fmt::Debug","std::marker::StructuralPartialEq"],"Insert":["std::cmp::PartialEq","std::fmt::Debug","std::marker::StructuralPartialEq"],"string_diff::EditDistance":["string_diff::OperationScore"]},"targets":{"<Delete as std::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/lib.rs\"))","std::fmt::Debug"],"<Insert as std::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/lib.rs\"))","std::fmt::Debug"],"<string_diff::EditDistance as string_diff::OperationScore>::delete_score":["delete_score","Real(LocalPath(\"src/string_diff.rs\"))","string_diff::OperationScore"],"<string_diff::EditDistance as string_diff::OperationScore>::insert_score":["insert_score","Real(LocalPath(\"src/string_diff.rs\"))","string_diff::OperationScore"],"<string_diff::EditDistance as string_diff::OperationScore>::match_score":["match_score","Real(LocalPath(\"src/string_diff.rs\"))","string_diff::OperationScore"],"<string_diff::EditDistance as string_diff::OperationScore>::substitution_score":["substitution_score","Real(LocalPath(\"src/string_diff.rs\"))","string_diff::OperationScore"],"Delete::compress_to":["compress_to","Real(LocalPath(\"src/lib.rs\"))",""],"Delete::expand_from":["expand_from","Real(LocalPath(\"src/lib.rs\"))",""],"Delete::get_length":["get_length","Real(LocalPath(\"src/lib.rs\"))",""],"Delete::get_position":["get_position","Real(LocalPath(\"src/lib.rs\"))",""],"Diff::add_delete":["add_delete","Real(LocalPath(\"src/lib.rs\"))",""],"Diff::add_insert":["add_insert","Real(LocalPath(\"src/lib.rs\"))",""],"Diff::apply":["apply","Real(LocalPath(\"src/lib.rs\"))",""],"Diff::apply_to_string":["apply_to_string","Real(LocalPath(\"src/lib.rs\"))",""],"Diff::compress_to":["compress_to","Real(LocalPath(\"src/lib.rs\"))",""],"Diff::deletes":["deletes","Real(LocalPath(\"src/lib.rs\"))",""],"Diff::expand_from":["expand_from","Real(LocalPath(\"src/lib.rs\"))",""],"Diff::inserts":["inserts","Real(LocalPath(\"src/lib.rs\"))",""],"Diff::is_empty":["is_empty","Real(LocalPath(\"src/lib.rs\"))",""],"Diff::new":["new","Real(LocalPath(\"src/lib.rs\"))",""],"Insert::compress_to":["compress_to","Real(LocalPath(\"src/lib.rs\"))",""],"Insert::expand_from":["expand_from","Real(LocalPath(\"src/lib.rs\"))",""],"Insert::get_data":["get_data","Real(LocalPath(\"src/lib.rs\"))",""],"Insert::get_position":["get_position","Real(LocalPath(\"src/lib.rs\"))",""],"hashing::<impl BlockHashes>::check_match":["check_match","Real(LocalPath(\"src/hashing.rs\"))",""],"hashing::<impl BlockHashes>::compress_to":["compress_to","Real(LocalPath(\"src/hashing.rs\"))",""],"hashing::<impl BlockHashes>::diff_and_update":["diff_and_update","Real(LocalPath(\"src/hashing.rs\"))",""],"hashing::<impl BlockHashes>::empty":["empty","Real(LocalPath(\"src/hashing.rs\"))",""],"hashing::<impl BlockHashes>::expand_from":["expand_from","Real(LocalPath(\"src/hashing.rs\"))",""],"hashing::<impl BlockHashes>::hash_match":["hash_match","Real(LocalPath(\"src/hashing.rs\"))",""],"hashing::<impl BlockHashes>::new":["new","Real(LocalPath(\"src/hashing.rs\"))",""],"hashing::<impl BlockHashes>::verify_unchanged":["verify_unchanged","Real(LocalPath(\"src/hashing.rs\"))",""],"hashing::RollingHash::get_hash":["get_hash","Real(LocalPath(\"src/hashing.rs\"))",""],"hashing::RollingHash::hash_buffer":["hash_buffer","Real(LocalPath(\"src/hashing.rs\"))",""],"hashing::RollingHash::new":["new","Real(LocalPath(\"src/hashing.rs\"))",""],"hashing::RollingHash::roll_hash":["roll_hash","Real(LocalPath(\"src/hashing.rs\"))",""],"string_diff::find_diff":["find_diff","Real(LocalPath(\"src/string_diff.rs\"))",""],"string_diff::hirschberg":["hirschberg","Real(LocalPath(\"src/string_diff.rs\"))",""],"string_diff::nw_score":["nw_score","Real(LocalPath(\"src/string_diff.rs\"))",""],"window::<impl Window<R>>::advance":["advance","Real(LocalPath(\"src/window.rs\"))",""],"window::<impl Window<R>>::frame":["frame","Real(LocalPath(\"src/window.rs\"))",""],"window::<impl Window<R>>::frame_size":["frame_size","Real(LocalPath(\"src/window.rs\"))",""],"window::<impl Window<R>>::get_bytes_read":["get_bytes_read","Real(LocalPath(\"src/window.rs\"))",""],"window::<impl Window<R>>::get_head":["get_head","Real(LocalPath(\"src/window.rs\"))",""],"window::<impl Window<R>>::load_next_block":["load_next_block","Real(LocalPath(\"src/window.rs\"))",""],"window::<impl Window<R>>::new":["new","Real(LocalPath(\"src/window.rs\"))",""],"window::<impl Window<R>>::on_boundry":["on_boundry","Real(LocalPath(\"src/window.rs\"))",""]},"trait_to_struct":{"std::cmp::PartialEq":["BlockHashes","Delete","Diff","Insert"],"std::fmt::Debug":["BlockHashes","Delete","Diff","Insert"],"std::marker::StructuralPartialEq":["BlockHashes","Delete","Diff","Insert"],"string_diff::OperationScore":["string_diff::EditDistance"]},"type_to_def_path":{"BlockHashes":"BlockHashes","Delete":"Delete","Diff":"Diff","Insert":"Insert","Window<R>":"Window","hashing::RollingHash":"hashing::RollingHash","string_diff::EditDistance":"string_diff::EditDistance"}}